{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error u: 1.018732e+00\n",
      "Error v: 1.029615e+00\n",
      "Error p: 1.339418e+00\n",
      "Error l1: 100.00000%\n",
      "Error l2: 100.00000%\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from functools import partial\n",
    "from pyDOE import lhs\n",
    "import time\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.gridspec as gridspec\n",
    "from itertools import product, combinations\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../../Utilities/')\n",
    "#from utils_plots import * \n",
    "from plotting import *#newfig, savefig\n",
    "sys.path.insert(0, '.')\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "class NSNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NSNN, self).__init__()\n",
    "        self.linear_in = nn.Linear(3, 20, dtype=torch.float64)\n",
    "        self.linear_out = nn.Linear(20, 2, dtype=torch.float64)\n",
    "        self.layers = nn.ModuleList([nn.Linear(20, 20, dtype=torch.float64) for _ in range(9)])\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear_in(x)\n",
    "        for layer in self.layers:\n",
    "            x = self.act(layer(x))\n",
    "        x = self.linear_out(x)\n",
    "        return x     \n",
    "\n",
    "def derivative(dy: torch.Tensor, x: torch.Tensor, order: int = 1) -> torch.Tensor:\n",
    "    for i in range(order):\n",
    "        dy = torch.autograd.grad(\n",
    "            dy, x, grad_outputs = torch.ones_like(dy), create_graph=True, retain_graph=True\n",
    "        )[0]\n",
    "    return dy\n",
    "\n",
    "def plot_solution(X_star, u_star, index):\n",
    "    \n",
    "    lb = X_star.min(0)\n",
    "    ub = X_star.max(0)\n",
    "    nn = 200\n",
    "    x = np.linspace(lb[0], ub[0], nn)\n",
    "    y = np.linspace(lb[1], ub[1], nn)\n",
    "    X, Y = np.meshgrid(x,y)\n",
    "    \n",
    "    U_star = griddata(X_star, u_star.flatten(), (X, Y), method='cubic')\n",
    "    \n",
    "    plt.figure(index)\n",
    "    plt.pcolor(X,Y,U_star, cmap = 'jet')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    \n",
    "def axisEqual3D(ax):\n",
    "    extents = np.array([getattr(ax, 'get_{}lim'.format(dim))() for dim in 'xyz'])\n",
    "    sz = extents[:,1] - extents[:,0]\n",
    "    centers = np.mean(extents, axis=1)\n",
    "    maxsize = max(abs(sz))\n",
    "    r = maxsize/4\n",
    "    for ctr, dim in zip(centers, 'xyz'):\n",
    "        getattr(ax, 'set_{}lim'.format(dim))(ctr - r, ctr + r)\n",
    "        \n",
    "def f(model, x_train_pt, y_train_pt, t_train_pt):\n",
    "    psi_and_p = model(torch.stack((x_train_pt, y_train_pt, t_train_pt), axis = 1).view(-1, 3))\n",
    "    psi = psi_and_p[:,0:1]\n",
    "    p = psi_and_p[:,1:2]\n",
    "    \n",
    "    u = derivative(psi, y_train_pt, order=1)\n",
    "    v = -derivative(psi, x_train_pt, order=1)\n",
    "    \n",
    "    u_t = derivative(u, t_train_pt, order=1)\n",
    "    u_x = derivative(u, x_train_pt, order=1)\n",
    "    u_y = derivative(u, y_train_pt, order=1)\n",
    "    u_xx = derivative(u_x, x_train_pt, order=1)\n",
    "    u_yy = derivative(u_y, y_train_pt, order=1)\n",
    "    \n",
    "    v_t = derivative(v, t_train_pt, order=1)\n",
    "    v_x = derivative(v, x_train_pt, order=1)\n",
    "    v_y = derivative(v, y_train_pt, order=1)\n",
    "    v_xx = derivative(v_x, x_train_pt, order=1)\n",
    "    v_yy = derivative(v_y, y_train_pt, order=1)    \n",
    "    \n",
    "    p_x = derivative(p, x_train_pt, order=1)\n",
    "    p_y = derivative(p, y_train_pt, order=1)\n",
    "    \n",
    "    f_u = u_t + lambda_1*(u*u_x + v*u_y) + p_x - lambda_2*(u_xx + u_yy)\n",
    "    f_v = v_t + lambda_1*(u*v_x + v*v_y) + p_y - lambda_2*(v_xx + v_yy)\n",
    "    \n",
    "    return u, v, p, f_u, f_v\n",
    "\n",
    "set_seed(42)\n",
    "iter = 0\n",
    "\n",
    "N_train = 5000\n",
    "results = []\n",
    "\n",
    "# Load Data\n",
    "data = scipy.io.loadmat('../Data/cylinder_nektar_wake.mat')\n",
    "        \n",
    "U_star = data['U_star'] # N x 2 x T\n",
    "P_star = data['p_star'] # N x T\n",
    "t_star = data['t'] # T x 1\n",
    "X_star = data['X_star'] # N x 2\n",
    "\n",
    "N = X_star.shape[0]\n",
    "T = t_star.shape[0]\n",
    "\n",
    "# Rearrange Data \n",
    "XX = np.tile(X_star[:,0:1], (1,T)) # N x T\n",
    "YY = np.tile(X_star[:,1:2], (1,T)) # N x T\n",
    "TT = np.tile(t_star, (1,N)).T # N x T\n",
    "\n",
    "UU = U_star[:,0,:] # N x T\n",
    "VV = U_star[:,1,:] # N x T\n",
    "PP = P_star # N x T\n",
    "\n",
    "x = XX.flatten()[:,None] # NT x 1\n",
    "y = YY.flatten()[:,None] # NT x 1\n",
    "t = TT.flatten()[:,None] # NT x 1\n",
    "\n",
    "u = UU.flatten()[:,None] # NT x 1\n",
    "v = VV.flatten()[:,None] # NT x 1\n",
    "p = PP.flatten()[:,None] # NT x 1\n",
    "\n",
    "######################################################################\n",
    "######################## Noiseles Data ###############################\n",
    "######################################################################\n",
    "# Training Data    \n",
    "idx = np.random.choice(N*T, N_train, replace=False)\n",
    "x_train = x[idx,:]\n",
    "y_train = y[idx,:]\n",
    "t_train = t[idx,:]\n",
    "u_train = u[idx,:]\n",
    "v_train = v[idx,:]\n",
    "\n",
    "x_train_pt = torch.from_numpy(x_train)\n",
    "x_train_pt.requires_grad = True\n",
    "y_train_pt = torch.from_numpy(y_train)\n",
    "y_train_pt.requires_grad = True\n",
    "t_train_pt = torch.from_numpy(t_train)\n",
    "t_train_pt.requires_grad = True\n",
    "u_train_pt = torch.from_numpy(u_train)\n",
    "v_train_pt = torch.from_numpy(v_train)\n",
    "\n",
    "lambda_1 = torch.nn.Parameter(torch.zeros(1, requires_grad=True))\n",
    "lambda_2 = torch.nn.Parameter(torch.zeros(1, requires_grad=True))    \n",
    "lambda_1s = []\n",
    "lambda_2s = []\n",
    "images = []\n",
    "\n",
    "iter_num=100\n",
    "\n",
    "model_path = f'models/pt_model_NS_clean_{iter_num}.pt'\n",
    "model = NSNN()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Test Data\n",
    "snap = np.array([100])\n",
    "x_star = X_star[:,0:1]\n",
    "y_star = X_star[:,1:2]\n",
    "t_star = TT[:,snap]\n",
    "\n",
    "u_star = U_star[:,0,snap]\n",
    "v_star = U_star[:,1,snap]\n",
    "p_star = P_star[:,snap]   \n",
    "\n",
    "x_star_pt = torch.from_numpy(x_star)\n",
    "x_star_pt.requires_grad = True\n",
    "y_star_pt = torch.from_numpy(y_star)\n",
    "y_star_pt.requires_grad = True\n",
    "t_star_pt = torch.from_numpy(t_star)\n",
    "t_star_pt.requires_grad = True    \n",
    "\n",
    "u_pred, v_pred, p_pred, f_u_pred, f_v_pred = f(model, x_star_pt, y_star_pt, t_star_pt) \n",
    "u_pred = u_pred.detach().numpy()\n",
    "v_pred = v_pred.detach().numpy()\n",
    "p_pred = p_pred.detach().numpy()\n",
    "lambda_1_value = lambda_1.detach().numpy()   \n",
    "lambda_2_value = lambda_2.detach().numpy()   \n",
    "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
    "error_p = np.linalg.norm(p_star-p_pred,2)/np.linalg.norm(p_star,2)    \n",
    "error_lambda_1 = np.abs(lambda_1.detach().numpy() - 1.0)*100\n",
    "error_lambda_2 = np.abs(lambda_2.detach().numpy() - 0.01)/0.01 * 100\n",
    "        \n",
    "print('Error u: %e' % (error_u))    \n",
    "print('Error v: %e' % (error_v))    \n",
    "print('Error p: %e' % (error_p))     \n",
    "print('Error l1: %.5f%%' % (error_lambda_1))                             \n",
    "print('Error l2: %.5f%%' % (error_lambda_2))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_1_values_clean = pd.read_csv('outputs/lambda_1s_clean.csv')\n",
    "lambda_2_values_clean = pd.read_csv('outputs/lambda_2s_clean.csv')\n",
    "lambda_1_values_noisy = pd.read_csv('outputs/lambda_1s_noisy.csv')\n",
    "lambda_2_values_noisy = pd.read_csv('outputs/lambda_2s_noisy.csv')\n",
    "\n",
    "lambda_1_value_clean=lambda_1_values_clean['l1'][iter_num-1]\n",
    "lambda_2_value_clean=lambda_2_values_clean['l2'][iter_num-1]\n",
    "lambda_1_value_noisy=lambda_1_values_noisy['l1'][iter_num-1]\n",
    "lambda_2_value_noisy=lambda_2_values_noisy['l2'][iter_num-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReScience-PINNs-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
